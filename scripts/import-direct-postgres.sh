#!/bin/bash

# Import Direct dans PostgreSQL depuis les fichiers JSON
# =======================================================

set -e

# Couleurs
GREEN='\033[0;32m'
RED='\033[0;31m'
YELLOW='\033[0;33m'
NC='\033[0m'

log() {
    echo -e "${GREEN}[$(date +'%Y-%m-%d %H:%M:%S')]${NC} $1"
}

error() {
    echo -e "${RED}[$(date +'%Y-%m-%d %H:%M:%S')] ‚ùå $1${NC}"
}

warning() {
    echo -e "${YELLOW}[$(date +'%Y-%m-%d %H:%M:%S')] ‚ö†Ô∏è  $1${NC}"
}

# V√©rifier l'argument
if [ $# -ne 1 ]; then
    error "Usage: $0 <extraction_directory>"
    exit 1
fi

EXTRACTION_DIR="$1"

if [ ! -d "$EXTRACTION_DIR" ]; then
    error "Le r√©pertoire d'extraction n'existe pas: $EXTRACTION_DIR"
    exit 1
fi

log "üöÄ Import direct dans PostgreSQL"
log "üìÇ Source: $EXTRACTION_DIR"

# Fonction pour importer un fichier JSON dans PostgreSQL
import_json_table() {
    local json_file="$1"
    local table_name="$2"
    
    if [ ! -f "$json_file" ]; then
        warning "Fichier non trouv√©: $json_file"
        return 1
    fi
    
    # V√©rifier si le fichier contient des donn√©es
    local records=$(cat "$json_file" | jq '. | length' 2>/dev/null || echo "0")
    
    if [ "$records" = "0" ] || [ "$records" = "[]" ]; then
        log "‚è≠Ô∏è $table_name: vide ou invalide"
        return 0
    fi
    
    log "üîÑ Import de $table_name ($records enregistrements)"
    
    # Cr√©er un script SQL temporaire pour l'import
    local temp_sql="/tmp/import_${table_name}.sql"
    
    # D√©but de la transaction
    echo "BEGIN;" > "$temp_sql"
    echo "SET session_replication_role = 'replica';" >> "$temp_sql"
    
    # Vider la table
    echo "TRUNCATE TABLE $table_name CASCADE;" >> "$temp_sql"
    
    # G√©n√©rer les INSERT depuis le JSON
    cat "$json_file" | jq -r '.[] | 
        @json | 
        "INSERT INTO '"$table_name"' SELECT * FROM json_populate_record(NULL::'"$table_name"', '\''\(.)'\''::json) ON CONFLICT DO NOTHING;"
    ' >> "$temp_sql" 2>/dev/null || {
        warning "Impossible de parser le JSON pour $table_name"
        return 1
    }
    
    # Fin de la transaction
    echo "SET session_replication_role = 'origin';" >> "$temp_sql"
    echo "COMMIT;" >> "$temp_sql"
    
    # Ex√©cuter le script SQL
    if docker compose -f docker-compose.supabase.yml exec -T supabase-db psql -U postgres -d postgres < "$temp_sql" 2>/dev/null; then
        log "‚úÖ $table_name import√© avec succ√®s"
        rm -f "$temp_sql"
        return 0
    else
        warning "Erreur lors de l'import de $table_name"
        rm -f "$temp_sql"
        return 1
    fi
}

# Tables √† importer dans l'ordre (respect des d√©pendances)
TABLES=(
    "partners"
    "accommodations"
    "restaurants"
    "activities"
    "leisure_activities"
    "profiles"
    "subscriptions"
    "restaurant_reservations"
    "travel_reservations"
)

# Compteurs
SUCCESS=0
FAILED=0

# Importer chaque table
for table in "${TABLES[@]}"; do
    json_file="$EXTRACTION_DIR/${table}.json"
    if import_json_table "$json_file" "$table"; then
        ((SUCCESS++))
    else
        ((FAILED++))
    fi
done

# R√©sum√©
echo ""
log "üìä R√âSUM√â DE L'IMPORT"
log "‚úÖ Tables import√©es avec succ√®s: $SUCCESS"
if [ $FAILED -gt 0 ]; then
    warning "‚ùå Tables √©chou√©es: $FAILED"
fi

# V√©rifier les comptages
log "üîç V√©rification des donn√©es import√©es:"
for table in "${TABLES[@]}"; do
    count=$(docker compose -f docker-compose.supabase.yml exec -T supabase-db psql -U postgres -d postgres -t -c "SELECT COUNT(*) FROM $table;" 2>/dev/null | tr -d ' \n')
    if [ -n "$count" ] && [ "$count" != "0" ]; then
        log "  ‚úÖ $table: $count enregistrements"
    fi
done

log "‚ú® Import termin√©!"